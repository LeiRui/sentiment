{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jianshu.com/p/29aa3ad63f9d\n",
    "1. ç‰¹å¾å‘é‡åŒ–ï¼›\n",
    "2. æœ´ç´ è´å¶æ–¯åˆ†ç±»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv',encoding='utf-8')\n",
    "test_df = pd.read_csv('../data/20190520_test.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, review, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(train_df[train_df.isnull().values==True]) # find anomaly rows and fix by hand\n",
    "# print(test_df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jo bhi ap se tou behtar hoon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya Allah meri sister Affia ki madad farma</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeh khud chahta a is umar main shadi krna.  ha...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tc ? Apky mun xe exe alfax achy nae lgty ğŸ˜’ğŸ’ƒ</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review     label\n",
       "0   1                       Jo bhi ap se tou behtar hoon  Negative\n",
       "1   2          ya Allah meri sister Affia ki madad farma  Positive\n",
       "2   3  Yeh khud chahta a is umar main shadi krna.  ha...  Negative\n",
       "3   4        Tc ? Apky mun xe exe alfax achy nae lgty ğŸ˜’ğŸ’ƒ  Negative\n",
       "4   5                                               Good  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Phr tissuw se saaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jail Road Per Firing Se 1 Shakhs Janbahaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mehfil loot li aunty ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rehnay do butt sahb nay galiya boht deni hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Zabardast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          review\n",
       "0   1                              Phr tissuw se saaf\n",
       "1   2      Jail Road Per Firing Se 1 Shakhs Janbahaq \n",
       "2   3                         mehfil loot li aunty ne\n",
       "3   4  Rehnay do butt sahb nay galiya boht deni hain \n",
       "4   5                                      Zabardast "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6328, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Negative\n",
       "1     Positive\n",
       "2     Negative\n",
       "3     Negative\n",
       "4     Positive\n",
       "5     Negative\n",
       "6     Negative\n",
       "7     Positive\n",
       "8     Positive\n",
       "9     Negative\n",
       "10    Negative\n",
       "11    Negative\n",
       "12    Positive\n",
       "13    Positive\n",
       "14    Negative\n",
       "15    Positive\n",
       "16    Negative\n",
       "17    Negative\n",
       "18    Positive\n",
       "19    Negative\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(text):\n",
    "    if(text==\"Positive\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['encoded_label'] = train_df.label.apply(encode_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     1\n",
       "2     0\n",
       "3     0\n",
       "4     1\n",
       "5     0\n",
       "6     0\n",
       "7     1\n",
       "8     1\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    1\n",
       "13    1\n",
       "14    0\n",
       "15    1\n",
       "16    0\n",
       "17    0\n",
       "18    1\n",
       "19    0\n",
       "Name: encoded_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['encoded_label'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df[['ID','review']]\n",
    "y_train = train_df.encoded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_df[['ID','review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.åˆ†è¯ \n",
    "**è¿™é‡Œä¸»è¦é’ˆå¯¹è¡¨æƒ…ç¬¦å·åŠ ç©ºæ ¼éš”å¼€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/brendano/25521552453909400e2310b04f1b2ac9\n",
    "JUNK_RE = (\n",
    "    u'[' +\n",
    "    u'\\U00010000-\\U0001ffff' +\n",
    "    u'\\U00030000-\\U0010ffff' +\n",
    "    u'\\U0000e000-\\U0000efff' +\n",
    "    u'\\U00002500-\\U00002bff' +\n",
    "    u'\\U0000200B-\\U0000200D' +\n",
    "    u'\\U0000fe0e-\\U0000fe0f' +\n",
    "    u'\\u2026' +\n",
    "    u'\\u201c' +\n",
    "    u'\\u201d' +\n",
    "    u']+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punc = string.punctuation\n",
    "punc = punc.replace(\"-\", \"\") # don't remove hyphens\n",
    "print(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# åœ¨æ ‡ç‚¹ç¬¦å·ã€è¡¨æƒ…å’Œæ­£æ–‡æ–‡æœ¬ä¹‹é—´åŠ ç©ºæ ¼éš”å¼€ï¼Œå¹¶ä¸”èšé›†åœ¨ä¸€èµ·çš„æ ‡ç‚¹ç¬¦å·ä¸ä¼šéš”å¼€ï¼Œæ¯”å¦‚:)\n",
    "def add_space_to_punc_and_emoji(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub( r'([a-zA-Z])(['+punc+'])', r'\\1 \\2',text)\n",
    "  text = re.sub(r'(?='+JUNK_RE+r')', r\" \", text)\n",
    "  text = text[::-1]\n",
    "  text = re.sub(r'([a-zA-Z])(['+punc+'])', r'\\1 \\2',text)\n",
    "  text = re.sub(r'(?='+JUNK_RE+r')', r\" \", text)\n",
    "  text = text[::-1]\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tu aa to sae dekh kia kia sa ??? pilati ğŸ˜‚  ğŸ˜  ğŸ˜‹ sss :) ss . â€¦   \n"
     ]
    }
   ],
   "source": [
    "a=\"Tu aa to sae dekh kia kia sa??? pilatiğŸ˜‚ğŸ˜ğŸ˜‹sss:)ss.â€¦  \"\n",
    "b=add_space_to_punc_and_emoji(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_train['spaced_review'] = x_train.review.apply(add_space_to_punc_and_emoji)\n",
    "x_test['spaced_review'] = x_test.review.apply(add_space_to_punc_and_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         jo bhi ap se tou behtar hoon\n",
       "1            ya allah meri sister affia ki madad farma\n",
       "2    yeh khud chahta a is umar main shadi krna .  h...\n",
       "3      tc ? apky mun xe exe alfax achy nae lgty  ğŸ˜’  ğŸ’ƒ \n",
       "4                                                 good\n",
       "Name: spaced_review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['spaced_review'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                phr tissuw se saaf\n",
       "1        jail road per firing se 1 shakhs janbahaq \n",
       "2                           mehfil loot li aunty ne\n",
       "3    rehnay do butt sahb nay galiya boht deni hain \n",
       "4                                        zabardast \n",
       "Name: spaced_review, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test['spaced_review'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ç‰¹å¾å‘é‡åŒ– ï¼ˆè¯é¢‘çŸ©é˜µï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = 0.6 # åœ¨è¶…è¿‡è¿™ä¸€æ¯”ä¾‹çš„æ–‡æ¡£ä¸­å‡ºç°çš„å…³é”®è¯ï¼ˆè¿‡äºå¹³å‡¡ï¼‰ï¼Œå»é™¤æ‰ã€‚ \n",
    "# max_dfè¿™ä¸€é¡¹è®¾ç½®å°ä¸€ç‚¹ä¹Ÿä¸å½±å“ï¼Œå› ä¸ºå¾ˆå°æ¦‚ç‡ä¸€ä¸ªè¯åœ¨è¶…è¿‡ç”šè‡³ä¸€èˆ¬çš„å¥å­ä¸­å‡ºç°ã€‚\n",
    "\n",
    "min_df = 4 # åœ¨ä½äºè¿™ä¸€æ•°é‡çš„æ–‡æ¡£ä¸­å‡ºç°çš„å…³é”®è¯ï¼ˆè¿‡äºç‹¬ç‰¹ï¼‰ï¼Œå»é™¤æ‰ã€‚\n",
    "# min_dfè¿™ä¸€é¡¹è®¾ç½®å¤§ä¸€äº›å¯¹æœ€ç»ˆç•™ä¸‹çš„è¯å½±å“æŒºå¤§çš„ã€‚è¯´æ˜ç°åœ¨è¿™6000å¤šå¥å°æ ·æœ¬æ¯ä¸ªè¯çš„é‡å¤å‡ºç°ç‡å¹¶ä¸é«˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUNK_RE = (\n",
    "    u'[' +\n",
    "    u'\\U00010000-\\U0001ffff' +\n",
    "    u'\\U00030000-\\U0010ffff' +\n",
    "    u'\\U0000e000-\\U0000efff' +\n",
    "    u'\\U00002500-\\U00002bff' +\n",
    "    u'\\U0000200B-\\U0000200D' +\n",
    "    u'\\U0000fe0e-\\U0000fe0f' +\n",
    "    u']+')\n",
    "punc = string.punctuation\n",
    "punc = punc.replace(\"-\", \"\") # don't remove hyphens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df = max_df, \n",
    "                       min_df = min_df, \n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect = CountVectorizer(max_df = max_df, \n",
    "#                       min_df = min_df, \n",
    "#                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b|'+JUNK_RE)\n",
    "# è€ƒè™‘åŠ å…¥è¡¨æƒ…ä½œä¸ºç‰¹å¾åè€Œå‡†ç¡®ç‡è¿˜ä¸å¦‚ä¸åŠ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(?u): UNICODE_CHARACTER_CLASS\n",
    "\\\\b word boundary\n",
    "\\\\w word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect = CountVectorizer(strip_accents=None,stop_words=None,max_df = max_df, min_df = min_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_matrix = pd.DataFrame(vect.fit_transform(x_train.spaced_review).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tc ? apky mun xe exe alfax achy nae lgty  ğŸ˜’  ğŸ’ƒ '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.spaced_review[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achy\n",
      "apky\n",
      "mun\n",
      "nae\n"
     ]
    }
   ],
   "source": [
    "a=term_matrix.iloc[[3]]\n",
    "for i in range(a.shape[1]):\n",
    "    if(a.iloc[0][i]!=0):\n",
    "        print(term_matrix.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zarurat',\n",
       " 'zarye',\n",
       " 'zati',\n",
       " 'zaya',\n",
       " 'zayada',\n",
       " 'zealand',\n",
       " 'zehan',\n",
       " 'zehar',\n",
       " 'zehni',\n",
       " 'zehr',\n",
       " 'zia',\n",
       " 'ziada',\n",
       " 'zikar',\n",
       " 'zimedari',\n",
       " 'zinda',\n",
       " 'zindabad',\n",
       " 'zindage',\n",
       " 'zindagi',\n",
       " 'zindah',\n",
       " 'zindge',\n",
       " 'zindgi',\n",
       " 'ziyada',\n",
       " 'ziyadah',\n",
       " 'zor',\n",
       " 'zra',\n",
       " 'zuban',\n",
       " 'zulfiqar',\n",
       " 'zulm',\n",
       " 'zyada',\n",
       " 'zyda']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3268"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. è´å¶æ–¯åˆ†ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                  lowercase=True, max_df=0.6, max_features=None, min_df=4,\n",
       "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                  strip_accents=None, token_pattern='(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
       "                  tokenizer=None, vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534792594956325"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, x_train.spaced_review, y_train, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train.spaced_review, y_train)\n",
    "y_pred = pipe.predict(x_test.spaced_review)\n",
    "y_pred_proba = pipe.predict_proba(x_test.spaced_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[350:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.23809343e-01, 3.76190657e-01],\n",
       "       [9.99980236e-01, 1.97639265e-05],\n",
       "       [7.64355000e-01, 2.35645000e-01],\n",
       "       [8.82803768e-01, 1.17196232e-01],\n",
       "       [1.75912964e-01, 8.24087036e-01],\n",
       "       [9.77465059e-01, 2.25349412e-02],\n",
       "       [9.40632444e-01, 5.93675565e-02],\n",
       "       [6.81331150e-01, 3.18668850e-01],\n",
       "       [8.68808384e-01, 1.31191616e-01],\n",
       "       [9.75741898e-01, 2.42581019e-02]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(x_test.ID,y_pred_proba[:,1]), columns=[\"ID\",\"Pred\"])\n",
    "df.to_csv('result.csv', index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.éšæœºæ£®æ—\n",
    "https://blog.csdn.net/u010665216/article/details/78741159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                  lowercase=True, max_df=0.6, max_features=None, min_df=4,\n",
       "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                  strip_accents=None, token_pattern='(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
       "                  tokenizer=None, vocabulary=None)),\n",
       " ('randomforestclassifier',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=None, oob_score=False, random_state=None,\n",
       "                         verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "pipe = make_pipeline(vect, forest)\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7269242351130754"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, x_train.spaced_review, y_train, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train.spaced_review, y_train)\n",
    "y_pred = pipe.predict(x_test.spaced_review)\n",
    "y_pred_proba = pipe.predict_proba(x_test.spaced_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86744186, 0.13255814],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.68707394, 0.31292606],\n",
       "       [0.42116667, 0.57883333],\n",
       "       [0.00744186, 0.99255814],\n",
       "       [0.6       , 0.4       ],\n",
       "       [0.46      , 0.54      ],\n",
       "       [0.66091125, 0.33908875],\n",
       "       [0.57      , 0.43      ],\n",
       "       [0.78      , 0.22      ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TfidfVectorizer\n",
    "vectorizer = CountVectorizer() #æ„å»ºä¸€ä¸ªè®¡ç®—è¯é¢‘ï¼ˆTFï¼‰çš„ç©æ„å„¿ï¼Œå½“ç„¶è¿™é‡Œé¢ä¸è¶³æ˜¯å¯ä»¥åšè¿™äº›\n",
    "\n",
    "transformer = TfidfTransformer() #æ„å»ºä¸€ä¸ªè®¡ç®—TF-IDFçš„ç©æ„å„¿\n",
    "\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "#vectorizer.fit_transform(corpus)å°†æ–‡æœ¬corpusè¾“å…¥ï¼Œå¾—åˆ°è¯é¢‘çŸ©é˜µ\n",
    "\n",
    "#å°†è¿™ä¸ªçŸ©é˜µä½œä¸ºè¾“å…¥ï¼Œç”¨transformer.fit_transform(è¯é¢‘çŸ©é˜µ)å¾—åˆ°TF-IDFæƒé‡çŸ©é˜µ\n",
    "\n",
    "https://www.jianshu.com/p/c7e2771eccaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "...     'This is the first document.',\n",
    "...     'This document is the second document.',\n",
    "...     'And this is the third one.',\n",
    "...     'Is this the first document?',\n",
    "... ]\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "tfidf_model = TfidfVectorizer().fit(corpus)\n",
    "X = tfidf_model.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "X_dense = X.todense()\n",
    "print(X_dense)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_model.vocabulary_)                      # è¯è¯­ä¸åˆ—çš„å¯¹åº”å…³ç³»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­£å¼ç”¨åœ¨è¿™é‡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(min_df=2, max_features = None,\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_term_matrix = pd.DataFrame(tf_vect.fit_transform(x_train.spaced_review).toarray(), columns=tf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaap</th>\n",
       "      <th>aaaya</th>\n",
       "      <th>aabad</th>\n",
       "      <th>aadmi</th>\n",
       "      <th>aae</th>\n",
       "      <th>aaega</th>\n",
       "      <th>aafia</th>\n",
       "      <th>...</th>\n",
       "      <th>zorr</th>\n",
       "      <th>zra</th>\n",
       "      <th>zror</th>\n",
       "      <th>zrort</th>\n",
       "      <th>zuban</th>\n",
       "      <th>zulam</th>\n",
       "      <th>zulfiqar</th>\n",
       "      <th>zulm</th>\n",
       "      <th>zyada</th>\n",
       "      <th>zyda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6823 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a1   aa  aaaa  aaap  aaaya  aabad  aadmi  aae  aaega  aafia  ...  zorr  \\\n",
       "0  0.0  0.0   0.0   0.0    0.0    0.0    0.0  0.0    0.0    0.0  ...   0.0   \n",
       "1  0.0  0.0   0.0   0.0    0.0    0.0    0.0  0.0    0.0    0.0  ...   0.0   \n",
       "2  0.0  0.0   0.0   0.0    0.0    0.0    0.0  0.0    0.0    0.0  ...   0.0   \n",
       "3  0.0  0.0   0.0   0.0    0.0    0.0    0.0  0.0    0.0    0.0  ...   0.0   \n",
       "4  0.0  0.0   0.0   0.0    0.0    0.0    0.0  0.0    0.0    0.0  ...   0.0   \n",
       "\n",
       "   zra  zror  zrort  zuban  zulam  zulfiqar  zulm  zyada  zyda  \n",
       "0  0.0   0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0  \n",
       "1  0.0   0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0  \n",
       "2  0.0   0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0  \n",
       "3  0.0   0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0  \n",
       "4  0.0   0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 6823 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_term_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achy 0.31489548800592204\n",
      "apky 0.346164723487749\n",
      "exe 0.39041186426831476\n",
      "lgty 0.37743395896957604\n",
      "mun 0.346164723487749\n",
      "nae 0.2672548704308224\n",
      "tc 0.39041186426831476\n",
      "xe 0.37743395896957604\n"
     ]
    }
   ],
   "source": [
    "a=tf_term_matrix.iloc[[3]]\n",
    "for i in range(a.shape[1]):\n",
    "    if(a.iloc[0][i]!=0):\n",
    "        print(tf_term_matrix.columns[i],a.iloc[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6823"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidfvectorizer',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                  input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                  min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                  smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                  sublinear_tf=False, token_pattern='(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
       "                  tokenizer=None, use_idf=True, vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "pipe = make_pipeline(tf_vect, nb)\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8511839628293603"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, x_train.spaced_review, y_train, cv=5, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train.spaced_review, y_train)\n",
    "y_pred = pipe.predict(x_test.spaced_review)\n",
    "y_pred_proba = pipe.predict_proba(x_test.spaced_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6225683 , 0.3774317 ],\n",
       "       [0.96914319, 0.03085681],\n",
       "       [0.5080556 , 0.4919444 ],\n",
       "       [0.58508193, 0.41491807],\n",
       "       [0.12669064, 0.87330936],\n",
       "       [0.83735578, 0.16264422],\n",
       "       [0.43919091, 0.56080909],\n",
       "       [0.54471072, 0.45528928],\n",
       "       [0.45319455, 0.54680545],\n",
       "       [0.66184704, 0.33815296]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(x_test.ID,y_pred_proba[:,1]), columns=[\"ID\",\"Pred\"])\n",
    "df.to_csv('result.csv', index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
