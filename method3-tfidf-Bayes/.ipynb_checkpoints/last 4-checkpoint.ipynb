{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, review, label]\n",
      "Index: []\n",
      "   ID                                             review     label\n",
      "0   1                       Jo bhi ap se tou behtar hoon  Negative\n",
      "1   2          ya Allah meri sister Affia ki madad farma  Positive\n",
      "2   3  Yeh khud chahta a is umar main shadi krna.  ha...  Negative\n",
      "3   4        Tc ? Apky mun xe exe alfax achy nae lgty ğŸ˜’ğŸ’ƒ  Negative\n",
      "4   5                                               Good  Positive\n",
      "   ID                                             review\n",
      "0   1                         masha allah ache cheez hai\n",
      "1   2  Wazir e Mumlikat Saira Afzal K Walid Ko Shikas...\n",
      "2   3                          SelfieKing Ban Gia Dulha \n",
      "3   4  Buhat he ache quality ke product hay.... i lov...\n",
      "4   5  Hahahah :p naam letaa tu ziada ddoubt hootaa m...\n",
      "(6328, 3)\n",
      "0    Negative\n",
      "1    Positive\n",
      "2    Negative\n",
      "3    Negative\n",
      "4    Positive\n",
      "5    Negative\n",
      "6    Negative\n",
      "7    Positive\n",
      "8    Positive\n",
      "9    Negative\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('../data/train.csv',encoding='utf-8')\n",
    "test_df = pd.read_csv('../data/20190527_test.csv',encoding='utf-8')\n",
    "\n",
    "print(train_df[train_df.isnull().values==True]) # find anomaly rows and fix by hand\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df['label'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(text):\n",
    "    if(text==\"Positive\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    0\n",
       "6    0\n",
       "7    1\n",
       "8    1\n",
       "9    0\n",
       "Name: encoded_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['encoded_label'] = train_df.label.apply(encode_label)\n",
    "train_df['encoded_label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df[['ID','review']]\n",
    "y_train = train_df.encoded_label\n",
    "x_test = test_df[['ID','review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def review_to_wordlist(review):\n",
    "    '''\n",
    "    æŠŠIMDBçš„è¯„è®ºè½¬æˆè¯åºåˆ—\n",
    "    å‚è€ƒï¼šhttp://blog.csdn.net/longxinchen_ml/article/details/50629613\n",
    "    '''\n",
    "    # å»æ‰HTMLæ ‡ç­¾ï¼Œæ‹¿åˆ°å†…å®¹\n",
    "    review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    # ç”¨æ­£åˆ™è¡¨è¾¾å¼å–å‡ºç¬¦åˆè§„èŒƒçš„éƒ¨åˆ†\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    # å°å†™åŒ–æ‰€æœ‰çš„è¯ï¼Œå¹¶è½¬æˆè¯list\n",
    "    words = review_text.lower().split()\n",
    "    # \n",
    "    new_review = \" \".join(words)\n",
    "    return new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tu aa to sae dekh kia kia sa pilati sss ss\n"
     ]
    }
   ],
   "source": [
    "a=\"Tu aa to sae dekh kia kia sa??? pilatiğŸ˜‚ğŸ˜ğŸ˜‹sss:)ss.â€¦  \"\n",
    "b=review_to_wordlist(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_train['spaced_review'] = x_train.review.apply(review_to_wordlist)\n",
    "x_test['spaced_review'] = x_test.review.apply(review_to_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         jo bhi ap se tou behtar hoon\n",
       "1            ya allah meri sister affia ki madad farma\n",
       "2    yeh khud chahta a is umar main shadi krna had ogi\n",
       "3               tc apky mun xe exe alfax achy nae lgty\n",
       "4                                                 good\n",
       "Name: spaced_review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['spaced_review'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           masha allah ache cheez hai\n",
       "1    wazir e mumlikat saira afzal k walid ko shikas...\n",
       "2                             selfieking ban gia dulha\n",
       "3    buhat he ache quality ke product hay i love da...\n",
       "4    hahahah p naam letaa tu ziada ddoubt hootaa ma...\n",
       "Name: spaced_review, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test['spaced_review'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, # æœ€å°æ”¯æŒåº¦ä¸º2\n",
    "           max_features=None,\n",
    "           strip_accents='unicode',\n",
    "           analyzer='word',\n",
    "           token_pattern=r'\\w{1,}',\n",
    "           ngram_range=(1, 3),  # äºŒå…ƒæ–‡æ³•æ¨¡å‹\n",
    "           use_idf=1,\n",
    "           smooth_idf=1,\n",
    "           sublinear_tf=1,\n",
    "           stop_words = 'english') # å»æ‰è‹±æ–‡åœç”¨è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = x_train['spaced_review'].tolist() + x_test['spaced_review'].tolist()\n",
    "print(len(data_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n",
      "TF-IDFå¤„ç†ç»“æŸ.\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(data_all)\n",
    "data_all = vectorizer.transform(data_all)\n",
    "len_train = len(x_train['spaced_review'])\n",
    "print(len_train)\n",
    "# æ¢å¤æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ¨åˆ†\n",
    "train_x = data_all[:len_train]\n",
    "test_x = data_all[len_train:]\n",
    "print ('TF-IDFå¤„ç†ç»“æŸ.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.8631329048865058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "model_NB = MNB()\n",
    "model_NB.fit(train_x, train_df.encoded_label)\n",
    "MNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "print (\"å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: \", np.mean(cross_val_score(model_NB, train_x, train_df.encoded_label, cv=10, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = np.array(model_NB.predict_proba(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13321244 0.86678756]\n",
      " [0.31632954 0.68367046]\n",
      " [0.65443442 0.34556558]\n",
      " [0.10934261 0.89065739]\n",
      " [0.62783136 0.37216864]\n",
      " [0.31400403 0.68599597]\n",
      " [0.21524792 0.78475208]\n",
      " [0.45230454 0.54769546]\n",
      " [0.33818958 0.66181042]\n",
      " [0.52465364 0.47534636]]\n"
     ]
    }
   ],
   "source": [
    "print(test_predicted[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(x_test.ID,test_predicted[:,1]), columns=[\"ID\",\"Pred\"])\n",
    "df.to_csv('result.csv', index=False, float_format='%.6f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
