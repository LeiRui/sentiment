{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/qq_39309652/article/details/90399674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    '''\n",
    "    把IMDB的评论转成词序列\n",
    "    参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613\n",
    "    '''\n",
    "    # 去掉HTML标签，拿到内容\n",
    "    review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    # 用正则表达式取出符合规范的部分\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    # 小写化所有的词，并转成词list\n",
    "    words = review_text.lower().split()\n",
    "    # \n",
    "    new_review = \" \".join(words)\n",
    "    return new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tu aa to sae dekh kia kia sa pilati sss ss\n"
     ]
    }
   ],
   "source": [
    "a=review_to_wordlist(\"Tu aa to sae dekh kia kia sa??? pilati😂😎😋sss:)ss.…  \")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                             review     label\n",
      "0   1                       Jo bhi ap se tou behtar hoon  Negative\n",
      "1   2          ya Allah meri sister Affia ki madad farma  Positive\n",
      "2   3  Yeh khud chahta a is umar main shadi krna.  ha...  Negative\n",
      "3   4        Tc ? Apky mun xe exe alfax achy nae lgty 😒💃  Negative\n",
      "4   5                                               Good  Positive\n",
      "   ID                                          review\n",
      "0   1                              Phr tissuw se saaf\n",
      "1   2      Jail Road Per Firing Se 1 Shakhs Janbahaq \n",
      "2   3                         mehfil loot li aunty ne\n",
      "3   4  Rehnay do butt sahb nay galiya boht deni hain \n",
      "4   5                                      Zabardast \n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "train = pd.read_csv('../data/train.csv', header=0)\n",
    "test = pd.read_csv('../data/20190527_test.csv', header=0)\n",
    "print (train.head())\n",
    "print (test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.review.apply(review_to_wordlist).tolist()\n",
    "test_data = test.review.apply(review_to_wordlist).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jo bhi ap se tou behtar hoon', 'ya allah meri sister affia ki madad farma', 'yeh khud chahta a is umar main shadi krna had ogi', 'tc apky mun xe exe alfax achy nae lgty', 'good', 'american president john f kennedy aur in ke bhai robert kennedy se bhi marilyn monroe ke affairs ka charcha raha', 'commission aur kickback ka dor dora raha quomi assase koriyon ke mol farokhat keye gaye', 'allah pak nazer e bd sy bechye or humesha bohat tarkian dy ameeen', 'amoman log samajhte hain ke jhok siyal hi abid ali ki pheli serial thi halan ke sach ye hai ke unhon ne sab se phele saleem chishtti le likhe howe kheel zanjeer mein adakari ki', 'akki khanyani k tum v good wesy tum shkll sy bhi khesiani billi kgti ho']\n",
      "['phr tissuw se saaf', 'jail road per firing se shakhs janbahaq', 'mehfil loot li aunty ne', 'rehnay do butt sahb nay galiya boht deni hain', 'zabardast', 'ap jahil ho', 'phir tm sab kahti ho k larko ko hamri id kahan se milti ha yu khula tag marogi to rozay me hamri eid hi hogi p p', 'buzdilun se kya gilah pakistanyu', 'punjabi filmoo ka hero ban ny ki kosish me hota ha na islye', 'bus ok ha yeh yar sahe ni ha']\n",
      "6328\n",
      "2712\n"
     ]
    }
   ],
   "source": [
    "# 预览数据\n",
    "print (train_data[:10])\n",
    "print (test_data[:10])\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(text):\n",
    "    if(text==\"Positive\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train.label.apply(encode_label).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF处理结束.\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "# 参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613\n",
    "tfidf = TFIDF(min_df=2, # 最小支持度为2\n",
    "           max_features=None,\n",
    "           strip_accents='unicode',\n",
    "           analyzer='word',\n",
    "           token_pattern=r'\\w{1,}',\n",
    "           ngram_range=(1, 3),  # 二元文法模型\n",
    "           use_idf=1,\n",
    "           smooth_idf=1,\n",
    "           sublinear_tf=1,\n",
    "           stop_words = 'english') # 去掉英文停用词\n",
    "\n",
    "# 合并训练和测试集以便进行TFIDF向量化操作\n",
    "data_all = train_data + test_data\n",
    "len_train = len(train_data)\n",
    "\n",
    "tfidf.fit(data_all)\n",
    "data_all = tfidf.transform(data_all)\n",
    "# 恢复成训练集和测试集部分\n",
    "train_x = data_all[:len_train]\n",
    "test_x = data_all[len_train:]\n",
    "print ('TF-IDF处理结束.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项式贝叶斯分类器10折交叉验证得分:  0.8631329048865058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "model_NB = MNB()\n",
    "model_NB.fit(train_x, label)\n",
    "MNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "print (\"多项式贝叶斯分类器10折交叉验证得分: \", np.mean(cross_val_score(model_NB, train_x, label, cv=10, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = np.array(model_NB.predict_proba(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63226051 0.36773949]\n",
      " [0.97693053 0.02306947]\n",
      " [0.59545547 0.40454453]\n",
      " [0.62338105 0.37661895]\n",
      " [0.12465368 0.87534632]\n",
      " [0.85289353 0.14710647]\n",
      " [0.53291268 0.46708732]\n",
      " [0.57255214 0.42744786]\n",
      " [0.46348977 0.53651023]\n",
      " [0.67855174 0.32144826]]\n"
     ]
    }
   ],
   "source": [
    "print(test_predicted[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(test.ID,test_predicted[:,1]), columns=[\"ID\",\"Pred\"])\n",
    "df.to_csv('result.csv', index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
